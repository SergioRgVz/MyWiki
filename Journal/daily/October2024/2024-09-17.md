- Intentar lanzar entorno docker con el entorno de conda en el servidor
- Copiar carpeta de entrenador a mi maquina
- Montar contenedor docker en mi máquina para lanzar entrenamiento
- Búsqueda de datasets de segmentación de ropa

Me ha comentado thomas que haga una prueba de Yolov8-seg para entrenar con FashionPedia

# DATASET FASHIONPEDIA (https://fashionpedia.github.io/home/index.html)

# 
https://learnopencv.com/train-yolov8-instance-segmentation/

Formato Ultralytics para dataset: https://docs.ultralytics.com/datasets/segment/#adding-your-own-dataset

Formato anotaciones FashionPedia: (https://github.com/cvdfoundation/fashionpedia)

Script para pasar de json grande de fashionPedia a fichero por foto:
```Python
import json
import pandas as pd
import os
from tqdm import tqdm

def load_json_to_dataframes(file_path):
    with open(file_path, 'r') as f:
        data = json.load(f)
    
    images_df = pd.DataFrame(data['images'])
    annotations_df = pd.DataFrame(data['annotations'])
    categories_df = pd.DataFrame(data['categories'])
    
    return images_df, annotations_df, categories_df

def create_label_files(images_df, annotations_df, categories_df, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    
    category_map = dict(zip(categories_df['id'], categories_df['name']))
    
    grouped_annotations = annotations_df.groupby('image_id')
    
    for index, image in tqdm(images_df.iterrows(), total=len(images_df), desc="Procesando imágenes"):
        image_id = image['id']
        file_name = image['file_name']
        
        image_annotations = grouped_annotations.get_group(image_id) if image_id in grouped_annotations.groups else pd.DataFrame()
        
        labels = []
        for _, annotation in image_annotations.iterrows():
            category_id = annotation['category_id']
            category_name = category_map.get(category_id, f"Unknown_{category_id}")
            
            label = {
                'category': category_id,
                'bbox': annotation['bbox'],
                'area': annotation['area'],
                'iscrowd': annotation['iscrowd'],
                'attribute_ids': annotation.get('attribute_ids', [])
            }
            
            # Incluir segmentación
            if 'segmentation' in annotation:
                label['segmentation'] = annotation['segmentation']
            
            labels.append(label)
        
        image_data = {
            'file_name': file_name,
            'width': image['width'],
            'height': image['height'],
            'id': image_id,
            'license': image.get('license'),
            'time_captured': image.get('time_captured'),
            'original_url': image.get('original_url'),
            'isstatic': image.get('isstatic'),
            'kaggle_id': image.get('kaggle_id'),
            'labels': labels
        }
        
        output_file = os.path.join(output_dir, f"{image_id}.json")
        with open(output_file, 'w') as f:
            json.dump(image_data, f, indent=2)

# Uso del script
file_path = 'instances_attributes_train2020.json'
output_dir = 'labels/'

print("Cargando datos...")
images_df, annotations_df, categories_df = load_json_to_dataframes(file_path)

print("Creando archivos de etiquetas...")
create_label_files(images_df, annotations_df, categories_df, output_dir)

print("Proceso completado. Los archivos de etiquetas se han guardado en:", output_dir)
```

Script para pasar de formato fashion_pedia a formato yolo:
```Python
import json
import os
import glob

def normalize_coordinates(coords, width, height):
    return [
        coords[i] / width if i % 2 == 0 else coords[i] / height
        for i in range(len(coords))
    ]

def process_json_file(json_file_path, output_dir):
    with open(json_file_path, 'r') as f:
        data = json.load(f)

    # Create category to class ID mapping
    categories = list(set(obj['category'] for obj in data['labels']))
    category_to_id = {cat: i for i, cat in enumerate(categories)}

    # Image dimensions
    width, height = data['width'], data['height']

    # Generate YOLO segmentation format
    yolo_labels = []
    for obj in data['labels']:
        class_id = category_to_id[obj['category']]
        normalized_coords = normalize_coordinates(obj['segmentation'][0], width, height)
        yolo_line = f"{class_id} " + " ".join(map(str, normalized_coords))
        yolo_labels.append(yolo_line)

    # Write to label file in the output directory
    label_file_name = os.path.splitext(data['file_name'])[0] + '.txt'
    output_path = os.path.join(output_dir, label_file_name)
    with open(output_path, 'w') as f:
        f.write("\n".join(yolo_labels))

    print(f"Labels for {data['file_name']} have been written to {output_path}")
    return category_to_id

# Define input and output directories
input_dir = 'labels'
output_dir = 'labels_converted'

# Create output directory if it doesn't exist
os.makedirs(output_dir, exist_ok=True)

# Process all JSON files in the input directory
json_files = glob.glob(os.path.join(input_dir, '*.json'))
all_categories = {}

for json_file in json_files:
    print(f"Processing {json_file}...")
    category_to_id = process_json_file(json_file, output_dir)
    all_categories.update(category_to_id)

# Print overall category to class ID mapping
print("\nOverall Category to Class ID mapping:")
for cat, id in all_categories.items():
    print(f"{cat}: {id}")

# Save category mapping to a file
mapping_file = os.path.join(output_dir, 'category_mapping.txt')
with open(mapping_file, 'w') as f:
    for cat, id in all_categories.items():
        f.write(f"{cat}: {id}\n")
print(f"\nCategory mapping has been saved to {mapping_file}")
```

Script para poder usar pandas en el json
```Python
import json
import pandas as pd
from datetime import datetime

def load_json_to_dataframes(file_path):
    # Cargar el JSON
    with open(file_path, 'r') as f:
        data = json.load(f)
    
    # Crear DataFrames
    info_df = pd.DataFrame([data['info']])
    categories_df = pd.DataFrame(data['categories'])
    attributes_df = pd.DataFrame(data['attributes'])
    images_df = pd.DataFrame(data['images'])
    annotations_df = pd.DataFrame(data['annotations'])
    licenses_df = pd.DataFrame(data['licenses'])
    
    # Convertir columnas de fecha a datetime
    # info_df['date_created'] = pd.to_datetime(info_df['date_created'])
    # images_df['time_captured'] = pd.to_datetime(images_df['time_captured'])
    
    return {
        'info': info_df,
        'categories': categories_df,
        'attributes': attributes_df,
        'images': images_df,
        'annotations': annotations_df,
        'licenses': licenses_df
    }

# Uso del script
file_path = '/ultralytics/instances_attributes_train2020.json'
dataframes = load_json_to_dataframes(file_path)

# Ejemplos de consultas
# print("Información general:")
# print(dataframes['info'])

# print("\nPrimeras 5 categorías:")
# print(dataframes['categories'].head())

# print("\nNúmero total de imágenes:")
# print(len(dataframes['images']))

# Imprimir todas las categorías
print("\nTodas las categorías en el dataset:")
categories_df = dataframes['categories']
for index, row in categories_df.iterrows():
    print(f"ID: {row['id']}, Nombre: {row['name']}, Supercategoría: {row['supercategory']}")

# Estadísticas adicionales sobre las categorías
print("\nEstadísticas de las categorías:")
print(f"Número total de categorías: {len(categories_df)}")
# print("\nDistribución de niveles:")
# print(categories_df['level'].value_counts().sort_index())
# print("\nTop 10 supercategorías más comunes:")
# print(categories_df['supercategory'].value_counts().head(10))

# Visualización opcional (descomenta si tienes matplotlib instalado)
# import matplotlib.pyplot as plt
# plt.figure(figsize=(12, 6))
# categories_df['level'].value_counts().sort_index().plot(kind='bar')
# plt.title('Distribución de Niveles de Categorías')
# plt.xlabel('Nivel')
# plt.ylabel('Número de Categorías')
# plt.show()
```

Script de pintado de formato yolo-seg 
```Python
import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
from matplotlib.colors import LinearSegmentedColormap

# Create a custom colormap
colors = plt.cm.tab20(np.linspace(0, 1, 20))
custom_cmap = LinearSegmentedColormap.from_list("custom", colors, N=20)

def read_yolo_seg(txt_path, img_shape):
    with open(txt_path, 'r') as f:
        lines = f.readlines()
    
    masks = []
    for line in lines:
        data = line.strip().split()
        class_id = int(data[0])
        polygon = np.array([float(x) for x in data[1:]])
        polygon = polygon.reshape(-1, 2)
        polygon[:, 0] *= img_shape[1]  # scale x
        polygon[:, 1] *= img_shape[0]  # scale y
        polygon = polygon.astype(int)
        masks.append((class_id, polygon))
    
    return masks

def draw_masks(image, masks, alpha=0.5):
    overlay = image.copy()
    for class_id, polygon in masks:
        color = custom_cmap(class_id / 20)[:3]
        color = [int(c * 255) for c in color]
        cv2.fillPoly(overlay, [polygon], color)
    
    return cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)

def visualize_segmentation(image_path, label_path, output_path):
    # Read image
    image = cv2.imread(image_path)
    if image is None:
        print(f"Error: Unable to read image from {image_path}")
        return
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Read YOLO segmentation data
    masks = read_yolo_seg(label_path, image.shape)

    # Draw masks on image
    result = draw_masks(image, masks)

    # Save the visualization
    plt.figure(figsize=(12, 8))
    plt.imshow(result)
    plt.axis('off')
    plt.title(f'Segmentation Visualization: {os.path.basename(image_path)}')
    plt.savefig(output_path, bbox_inches='tight', pad_inches=0.1)
    plt.close()
    print(f"Visualization saved to {output_path}")

# Specific image and label paths
image_folder = './'
label_folder = 'labels_converted'
image_filename = '1b3869390b13480a9804b5f322eaa4e7.jpg'
label_filename = '1b3869390b13480a9804b5f322eaa4e7.txt'

image_path = os.path.join(image_folder, image_filename)
label_path = os.path.join(label_folder, label_filename)
output_filename = f'visualization_{os.path.splitext(image_filename)[0]}.png'
output_path = output_filename  # Save in the current directory

# Check if both files exist
if os.path.exists(image_path) and os.path.exists(label_path):
    print(f"Processing {image_filename}")
    visualize_segmentation(image_path, label_path, output_path)
else:
    if not os.path.exists(image_path):
        print(f"Error: Image file not found at {image_path}")
    if not os.path.exists(label_path):
        print(f"Error: Label file not found at {label_path}")
```



## ToDos mañana
![[Pasted image 20240917172242.png]]
- [ ] Comprobar las categorias que me estoy llevando con los scripts de limpieza y arreglarlo
- [ ] Lanzar entrenamiento de Yolov8 en Docker en este contenedor:
` sudo docker run -it --ipc=host --gpus all   --device=/dev/video0:/dev/video0   -e DISPLAY=:0   -v /tmp/.X11-unix:/tmp/.X11-unix   -v /path/to/your/script:/workspace/test.py   --network host   ultralytics/ultralytics:latest`

![[Pasted image 20240917173054.png]]https://docs.ultralytics.com/guides/docker-quickstart/?h=docker